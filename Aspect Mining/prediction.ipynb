{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = pd.read_csv('../data_concat/movies.csv') \n",
    "\n",
    "fb_1k = pd.read_table('../data/view_brand_rollup_facebook_1k-10k.tsv')\n",
    "fb_10k = pd.read_table('../data/view_brand_rollup_facebook_10kplus.tsv')\n",
    "fb = pd.concat([fb_1k, fb_10k])\n",
    "fb = pd.merge(fb, brand, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "\n",
    "insta_1k = pd.read_table('../data/view_brand_rollup_instagram_1k-10k.tsv')\n",
    "insta_10k = pd.read_table('../data/view_brand_rollup_instagram_10kplus.tsv')\n",
    "insta = pd.concat([insta_1k, insta_10k])\n",
    "insta = pd.merge(insta, brand, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')\n",
    "\n",
    "twit_1k = pd.read_table('../data/view_brand_rollup_twitter_1k-10k.tsv')\n",
    "twit_10k = pd.read_table('../data/view_brand_rollup_twitter_10kplus.tsv')\n",
    "twit = pd.concat([twit_1k, twit_10k])\n",
    "twit = pd.merge(twit, brand, left_on = 'movie_id', right_on = 'brand_ods_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb['data_for']= pd.to_datetime(fb['data_for']) \n",
    "fb['released_on'] = pd.to_datetime(fb['released_on'])\n",
    "fb['days_after_release'] = fb['data_for'] - fb['released_on'] \n",
    "fb = fb[(fb['days_after_release'] <= '0 days') & (fb['days_after_release'] >= '-365 days')]\n",
    "fb['days'] = fb['days_after_release'] + timedelta(days=365)\n",
    "\n",
    "insta['data_for']= pd.to_datetime(insta['data_for']) \n",
    "insta['released_on'] = pd.to_datetime(insta['released_on'])\n",
    "insta['days_after_release'] = insta['data_for'] - insta['released_on'] \n",
    "insta = insta[(insta['days_after_release'] <= '0 days') & (insta['days_after_release'] >= '-365 days')]\n",
    "insta['days'] = insta['days_after_release'] + timedelta(days=365)\n",
    "\n",
    "twit['data_for']= pd.to_datetime(twit['data_for']) \n",
    "twit['released_on'] = pd.to_datetime(twit['released_on'])\n",
    "twit['days_after_release'] = twit['data_for'] - twit['released_on'] \n",
    "twit = twit[(twit['days_after_release'] <= '0 days') & (twit['days_after_release'] >= '-365 days')]\n",
    "twit['days'] = twit['days_after_release'] + timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments = pd.read_csv('../data_concat/comments_with_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movie_data_w_bo.csv').dropna()\n",
    "movies['ProductionBudget'] = movies['ProductionBudget'].str.replace('[b\\$,\\']', '').astype('int64')\n",
    "movies['WorldwideGross'] = movies['WorldwideGross'].str.replace('[b\\$,\\']', '').astype('int64')\n",
    "\n",
    "movie = pd.read_csv('../data_concat/movies.csv')\n",
    "\n",
    "dat = pd.merge(movie, movies, left_on = 'replace', right_on = 'Movie', how = 'left')\n",
    "\n",
    "\n",
    "dat['profit'] = dat['WorldwideGross'] - dat['ProductionBudget']\n",
    "\n",
    "def success(profit):\n",
    "    if profit < 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "dat['success'] = dat['profit'].map(success)\n",
    "\n",
    "df = dat.drop(['X1', 'data_profile_dcs_uid', 'data_profile_channel_type', 'data_profile_source_type',\\\n",
    "              'data_affiliation_active_flag', 'data_affiliation_start_date_key', 'data_affiliation_end_date_key',\\\n",
    "              'budget', 'ticker_symbol', 'Unnamed: 0', 'date URL', \\\n",
    "              'ReleaseDate', 'summary URL', 'Movie'], axis = 1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add total_post_interaction for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_filter = list(np.arange(30, 365, 30))\n",
    "days_filter = ['-' + str(s) + ' days' for s in month_filter]\n",
    "\n",
    "fb_month = fb[fb['days_after_release'].isin(days_filter)]\n",
    "insta_month = insta[insta['days_after_release'].isin(days_filter)]\n",
    "twit_month = twit[twit['days_after_release'].isin(days_filter)]\n",
    "\n",
    "fb_month = fb_month.pivot(index = 'movie_id', columns = 'days_after_release',  values=['total_post_interactions'])\n",
    "insta_month = insta_month.pivot(index = 'movie_id', columns = 'days_after_release',  values=['total_post_interactions'])\n",
    "twit_month = twit_month.pivot(index = 'movie_id', columns = 'days_after_release',  values=['total_post_interactions'])\n",
    "\n",
    "fb_month.columns = fb_month.columns.droplevel(0)\n",
    "fb_month.columns = [s.replace(' ', '') + '_fb' for s in days_filter]\n",
    "insta_month.columns = insta_month.columns.droplevel(0)\n",
    "insta_month.columns = [s.replace(' ', '') + '_insta' for s in days_filter]\n",
    "twit_month.columns = twit_month.columns.droplevel(0)\n",
    "twit_month.columns = [s.replace(' ', '') + '_twit' for s in days_filter]\n",
    "\n",
    "df = pd.merge(df, fb_month, left_on = 'brand_ods_id', right_on = 'movie_id')\n",
    "df = pd.merge(df, insta_month, left_on = 'brand_ods_id', right_on = 'movie_id')\n",
    "df = pd.merge(df, twit_month, left_on = 'brand_ods_id', right_on = 'movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
